{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5dXu5a4-hno"
      },
      "outputs": [],
      "source": [
        "!pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('HF_TOKEN')\n",
        "import os\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import mlflow.transformers\n",
        "from dotenv import load_dotenv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_recall_fscore_support,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    AutoModel, pipeline, Trainer, TrainingArguments\n",
        ")\n",
        "from datasets import Dataset\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# MLflow Configuration\n",
        "os.environ['MLFLOW_TRACKING_USERNAME'] = os.getenv(userdata.get('username'))\n",
        "os.environ['MLFLOW_TRACKING_PASSWORD'] = os.getenv(userdata.get('password'))\n",
        "os.environ['MLFLOW_TRACKING_URI'] = os.getenv('MLFLOW_TRACKING_URI', 'https://mlflow.worldwidecheps.synology./')\n",
        "\n",
        "# Set MLflow experiment\n",
        "mlflow.set_experiment(\"steam-reviews-analysis\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 1. DATA LOADING\n",
        "# ============================================================================\n",
        "\n",
        "def load_data_from_sqlite(db_path, table_name=\"reviews\"):\n",
        "    \"\"\"Load labeled reviews from SQLite database\"\"\"\n",
        "    print(\"Loading data from SQLite...\")\n",
        "    conn = sqlite3.connect(db_path)\n",
        "\n",
        "    # Adjust column names according to your database schema\n",
        "    query = f\"\"\"\n",
        "    SELECT\n",
        "        review,\n",
        "        voted_up\n",
        "    FROM {table_name}\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_sql_query(query, conn)\n",
        "    conn.close()\n",
        "\n",
        "    print(f\"Loaded {len(df)} reviews\")\n",
        "    print(f\"Columns: {df.columns.tolist()}\")\n",
        "    print(f\"\\nSentiment distribution:\\n{df['sentiment_label'].value_counts()}\")\n",
        "    print(f\"\\nCategory distribution:\\n{df['product_category'].value_counts()}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 2. SENTIMENT CLASSIFICATION WITH TRANSFORMERS\n",
        "# ============================================================================\n",
        "\n",
        "class SentimentClassifier:\n",
        "    def __init__(self, model_name=\"distilbert-base-uncased\", num_labels=2):\n",
        "        \"\"\"\n",
        "        Initialize sentiment classifier\n",
        "        model_name options:\n",
        "        - distilbert-base-uncased (lightweight, fast)\n",
        "        - bert-base-uncased (strong general purpose)\n",
        "        - roberta-base (robust to nuances)\n",
        "        - cardiffnlp/twitter-roberta-base-sentiment (for short texts)\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.num_labels = num_labels\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    def prepare_data(self, texts, labels):\n",
        "        \"\"\"Prepare data for training\"\"\"\n",
        "        dataset = Dataset.from_dict({\n",
        "            'text': texts,\n",
        "            'label': labels\n",
        "        })\n",
        "        return dataset\n",
        "\n",
        "    def tokenize_function(self, examples):\n",
        "        \"\"\"Tokenize texts\"\"\"\n",
        "        return self.tokenizer(\n",
        "            examples['text'],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "\n",
        "    def train(self, train_texts, train_labels, val_texts, val_labels,\n",
        "              epochs=3, batch_size=16, learning_rate=2e-5):\n",
        "        \"\"\"Fine-tune transformer model\"\"\"\n",
        "\n",
        "        print(f\"\\nTraining {self.model_name} on {self.device}...\")\n",
        "\n",
        "        # Initialize tokenizer and model\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            self.model_name,\n",
        "            num_labels=self.num_labels\n",
        "        ).to(self.device)\n",
        "\n",
        "        # Prepare datasets\n",
        "        train_dataset = self.prepare_data(train_texts, train_labels)\n",
        "        val_dataset = self.prepare_data(val_texts, val_labels)\n",
        "\n",
        "        # Tokenize\n",
        "        train_dataset = train_dataset.map(self.tokenize_function, batched=True)\n",
        "        val_dataset = val_dataset.map(self.tokenize_function, batched=True)\n",
        "\n",
        "        # Training arguments\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir='./results',\n",
        "            num_train_epochs=epochs,\n",
        "            per_device_train_batch_size=batch_size,\n",
        "            per_device_eval_batch_size=batch_size,\n",
        "            learning_rate=learning_rate,\n",
        "            warmup_steps=500,\n",
        "            weight_decay=0.01,\n",
        "            logging_dir='./logs',\n",
        "            logging_steps=10,\n",
        "            evaluation_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            load_best_model_at_end=True,\n",
        "        )\n",
        "\n",
        "        # Trainer\n",
        "        trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "        )\n",
        "\n",
        "        # Train\n",
        "        trainer.train()\n",
        "\n",
        "        return trainer\n",
        "\n",
        "    def predict(self, texts):\n",
        "        \"\"\"Make predictions\"\"\"\n",
        "        self.model.eval()\n",
        "        predictions = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for text in texts:\n",
        "                inputs = self.tokenizer(\n",
        "                    text,\n",
        "                    return_tensors=\"pt\",\n",
        "                    truncation=True,\n",
        "                    max_length=512,\n",
        "                    padding=True\n",
        "                ).to(self.device)\n",
        "\n",
        "                outputs = self.model(**inputs)\n",
        "                pred = torch.argmax(outputs.logits, dim=1).cpu().numpy()[0]\n",
        "                predictions.append(pred)\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "\n",
        "def evaluate_sentiment_model(y_true, y_pred, class_names=['Negative', 'Positive']):\n",
        "    \"\"\"Comprehensive model evaluation\"\"\"\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average=None\n",
        "    )\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SENTIMENT CLASSIFICATION RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nOverall Accuracy: {accuracy*100:.2f}%\\n\")\n",
        "\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    print(\"-\" * 60)\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        print(f\"{class_name}:\")\n",
        "        print(f\"  Precision: {precision[i]*100:.2f}%\")\n",
        "        print(f\"  Recall:    {recall[i]*100:.2f}%\")\n",
        "        print(f\"  F1-Score:  {f1[i]*100:.2f}%\")\n",
        "        print()\n",
        "\n",
        "    # Classification report\n",
        "    print(\"\\nDetailed Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save plot\n",
        "    cm_path = 'confusion_matrix.png'\n",
        "    plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'confusion_matrix': cm,\n",
        "        'cm_plot_path': cm_path\n",
        "    }"
      ],
      "metadata": {
        "id": "qtdDXY72-jeY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}