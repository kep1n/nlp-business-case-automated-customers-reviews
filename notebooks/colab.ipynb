{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5dXu5a4-hno"
   },
   "outputs": [],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtdDXY72-jeY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/30 11:14:21 INFO mlflow.tracking.fluent: Experiment with name 'steam-reviews-fine-tune' does not exist. Creating a new experiment.\n",
      "2025/12/30 11:14:24 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
      "2025/12/30 11:14:24 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/12/30 11:14:24 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
      "2025/12/30 11:14:24 INFO mlflow.tracking.fluent: Autologging successfully enabled for transformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 1: LOADING DATA\n",
      "======================================================================\n",
      "âœ“ Loaded 37902 from train\n",
      "Sentiment distribution: Positive=18951, Negative=18951\n",
      "âœ“ Loaded 8122 from validation\n",
      "Sentiment distribution: Positive=4061, Negative=4061\n",
      "âœ“ Loaded 8122 from test\n",
      "Sentiment distribution: Positive=4061, Negative=4061\n",
      "Training set:   37902 samples\n",
      "Validation set: 8122 samples\n",
      "Test set:       8122 samples\n",
      "\n",
      "======================================================================\n",
      "STEP 3: TRAINING MODEL\n",
      "======================================================================\n",
      "Using device: cuda\n",
      "\n",
      "======================================================================\n",
      "FINE-TUNING DISTILBERT/DISTILBERT-BASE-UNCASED\n",
      "Using LoRA: True\n",
      "======================================================================\n",
      "Training samples: 37902\n",
      "Validation samples: 8122\n",
      "Epochs: 3\n",
      "Batch size: 16\n",
      "Learning rate: 0.0003\n",
      "\n",
      "Loading tokenizer and model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14336c3140f49189987a42989fa1ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbcf21cdb6045798f14615660a1fd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5e70af589b4f22ad9de48566aedc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6e74050b3748ea9ea7252671702e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73cdb54686245e4bdfd213a9be7f0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from google.colab import userdata\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.transformers\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    AutoModel, pipeline, Trainer, TrainingArguments\n",
    ")\n",
    "from datasets import Dataset\n",
    "from peft import (\n",
    "    LoraConfig, \n",
    "    get_peft_model, \n",
    "    TaskType,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# MLflow Configuration\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = userdata.get('username')\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = userdata.get('password')\n",
    "os.environ['MLFLOW_TRACKING_URI'] = ''\n",
    "\n",
    "# Set MLflow experiment\n",
    "mlflow.set_experiment(\"steam-reviews-fine-tune\")\n",
    "mlflow.autolog()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 1. DATA LOADING\n",
    "# ============================================================================\n",
    "\n",
    "def load_data_from_sqlite(db_path, table_name=\"train\"):\n",
    "    \"\"\"\n",
    "    Load labeled reviews from SQLite database\n",
    "    \n",
    "    Args:\n",
    "        db_path: Path to SQLite database\n",
    "        table_name: Name of the table (or base name if split is provided)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with reviews and sentiment labels\n",
    "    \"\"\"\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    # Adjust column names according to your database schema\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        review_text_clean,\n",
    "        voted_up\n",
    "    FROM {table_name}\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"âœ“ Loaded {len(df)} from {table_name}\")\n",
    "    \n",
    "    print(f\"Sentiment distribution: Positive={df['voted_up'].sum()}, Negative={(~df['voted_up'].astype(bool)).sum()}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 2. SENTIMENT CLASSIFICATION WITH PEFT/LoRA\n",
    "# ============================================================================\n",
    "\n",
    "class SentimentClassifierWithLoRA:\n",
    "    \"\"\"\n",
    "    Fine-tune transformer models using PEFT/LoRA for efficient training\n",
    "    \n",
    "    Benefits of LoRA:\n",
    "    - Train only 0.1-1% of parameters (much faster)\n",
    "    - Lower memory requirements\n",
    "    - Easy to save/share (adapter weights are tiny)\n",
    "    - Can switch between multiple adapters on same base model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"distilbert-base-uncased\", num_labels=2, use_lora=True):\n",
    "        \"\"\"\n",
    "        Initialize sentiment classifier with optional LoRA\n",
    "        \n",
    "        Recommended models:\n",
    "        - distilbert-base-uncased (lightweight, fast)\n",
    "        - bert-base-uncased (strong general purpose)\n",
    "        - roberta-base (robust to nuances)\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.num_labels = num_labels\n",
    "        self.use_lora = use_lora\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "    def prepare_data(self, texts, labels):\n",
    "        \"\"\"Prepare data for training\"\"\"\n",
    "        dataset = Dataset.from_dict({\n",
    "            'text': texts,\n",
    "            'label': labels\n",
    "        })\n",
    "        return dataset\n",
    "\n",
    "    def tokenize_function(self, examples):\n",
    "        \"\"\"Tokenize texts\"\"\"\n",
    "        return self.tokenizer(\n",
    "            examples['text'],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        )\n",
    "    \n",
    "    def compute_metrics(self, eval_pred):\n",
    "        \"\"\"Compute metrics during training\"\"\"\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            labels, predictions, average='weighted'\n",
    "        )\n",
    "        acc = accuracy_score(labels, predictions)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        }\n",
    "\n",
    "    def setup_lora_config(self):\n",
    "        \"\"\"\n",
    "        Configure LoRA parameters\n",
    "        \n",
    "        Key parameters:\n",
    "        - r: LoRA rank (4-16 typical, higher = more capacity but slower)\n",
    "        - lora_alpha: Scaling factor (typically 2*r)\n",
    "        - target_modules: Which layers to apply LoRA to\n",
    "        - lora_dropout: Dropout for LoRA layers\n",
    "        \"\"\"\n",
    "        lora_config = LoraConfig(\n",
    "            task_type=TaskType.SEQ_CLS,  # Sequence classification\n",
    "            r=8,  # LoRA rank - balance between performance and efficiency\n",
    "            lora_alpha=16,  # Scaling factor (2*r is common)\n",
    "            lora_dropout=0.1,  # Dropout for regularization\n",
    "            target_modules=[\"q_lin\", \"v_lin\"],  # For DistilBERT (query and value projections)\n",
    "            # For BERT/RoBERTa use: [\"query\", \"value\"] or [\"query\", \"key\", \"value\"]\n",
    "            bias=\"none\",  # Don't train bias terms\n",
    "            inference_mode=False,  # We're training, not inferencing\n",
    "        )\n",
    "        return lora_config\n",
    "\n",
    "    def train(self, train_texts, train_labels, val_texts, val_labels,\n",
    "              epochs=3, batch_size=16, learning_rate=3e-4,\n",
    "              output_dir='./results', lora_output_dir='./lora_adapter'):\n",
    "        \"\"\"\n",
    "        Fine-tune transformer model with LoRA\n",
    "        \n",
    "        Note: LoRA typically uses higher learning rates (1e-4 to 1e-3)\n",
    "        compared to full fine-tuning (2e-5 to 5e-5)\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"FINE-TUNING {self.model_name.upper()}\")\n",
    "        print(f\"Using LoRA: {self.use_lora}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Training samples: {len(train_texts)}\")\n",
    "        print(f\"Validation samples: {len(val_texts)}\")\n",
    "        print(f\"Epochs: {epochs}\")\n",
    "        print(f\"Batch size: {batch_size}\")\n",
    "        print(f\"Learning rate: {learning_rate}\")\n",
    "\n",
    "        # Initialize tokenizer\n",
    "        print(f\"\\nLoading tokenizer and model...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        \n",
    "        # Load base model\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.model_name,\n",
    "            num_labels=self.num_labels\n",
    "        )\n",
    "        \n",
    "        # Apply LoRA if enabled\n",
    "        if self.use_lora:\n",
    "            print(\"\\nðŸ”§ Applying LoRA configuration...\")\n",
    "            lora_config = self.setup_lora_config()\n",
    "            self.model = get_peft_model(self.model, lora_config)\n",
    "            \n",
    "            # Print trainable parameters\n",
    "            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "            total_params = sum(p.numel() for p in self.model.parameters())\n",
    "            print(f\"âœ“ Trainable params: {trainable_params:,} ({100 * trainable_params / total_params:.2f}%)\")\n",
    "            print(f\"  Total params: {total_params:,}\")\n",
    "            self.model.print_trainable_parameters()\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        # Prepare datasets\n",
    "        print(\"\\nPreparing datasets...\")\n",
    "        train_dataset = self.prepare_data(train_texts, train_labels)\n",
    "        val_dataset = self.prepare_data(val_texts, val_labels)\n",
    "\n",
    "        # Tokenize\n",
    "        print(\"Tokenizing...\")\n",
    "        train_dataset = train_dataset.map(self.tokenize_function, batched=True)\n",
    "        val_dataset = val_dataset.map(self.tokenize_function, batched=True)\n",
    "\n",
    "        # Training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            num_train_epochs=epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            warmup_steps=100,\n",
    "            weight_decay=0.01,\n",
    "            logging_dir='./logs',\n",
    "            logging_steps=50,\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1\",\n",
    "            greater_is_better=True,\n",
    "            report_to=\"none\",\n",
    "            fp16=torch.cuda.is_available(),\n",
    "        )\n",
    "\n",
    "        # Trainer\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            compute_metrics=self.compute_metrics,\n",
    "        )\n",
    "\n",
    "        # Train\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"TRAINING STARTED\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        trainer.train()\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"TRAINING COMPLETE\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        # Save the model\n",
    "        if self.use_lora:\n",
    "            print(f\"\\nðŸ’¾ Saving LoRA adapter to {lora_output_dir}...\")\n",
    "            self.model.save_pretrained(lora_output_dir)\n",
    "            self.tokenizer.save_pretrained(lora_output_dir)\n",
    "            print(f\"âœ“ LoRA adapter saved (only {self._get_dir_size(lora_output_dir):.2f} MB)\")\n",
    "        else:\n",
    "            print(f\"\\nðŸ’¾ Saving full model to {output_dir}...\")\n",
    "            self.model.save_pretrained(output_dir)\n",
    "            self.tokenizer.save_pretrained(output_dir)\n",
    "            print(f\"âœ“ Model saved\")\n",
    "\n",
    "        return trainer\n",
    "    \n",
    "    def _get_dir_size(self, path):\n",
    "        \"\"\"Get directory size in MB\"\"\"\n",
    "        total_size = 0\n",
    "        for dirpath, dirnames, filenames in os.walk(path):\n",
    "            for f in filenames:\n",
    "                fp = os.path.join(dirpath, f)\n",
    "                total_size += os.path.getsize(fp)\n",
    "        return total_size / (1024 * 1024)\n",
    "\n",
    "    def load_model(self, adapter_path='./lora_adapter', base_model_name=None):\n",
    "        \"\"\"\n",
    "        Load fine-tuned model\n",
    "        \n",
    "        For LoRA models:\n",
    "        - Loads base model + adapter weights\n",
    "        - Much faster than loading full model\n",
    "        \n",
    "        Args:\n",
    "            adapter_path: Path to LoRA adapter or full model\n",
    "            base_model_name: Base model name (if different from init)\n",
    "        \"\"\"\n",
    "        if base_model_name is None:\n",
    "            base_model_name = self.model_name\n",
    "            \n",
    "        print(f\"\\nLoading model from {adapter_path}...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(adapter_path)\n",
    "        \n",
    "        if self.use_lora:\n",
    "            # Load base model first\n",
    "            print(f\"Loading base model: {base_model_name}\")\n",
    "            base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                base_model_name,\n",
    "                num_labels=self.num_labels\n",
    "            )\n",
    "            \n",
    "            # Load LoRA adapter\n",
    "            print(\"Loading LoRA adapter...\")\n",
    "            self.model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "            \n",
    "            # Merge adapter with base model for faster inference (optional)\n",
    "            print(\"Merging adapter with base model for inference...\")\n",
    "            self.model = self.model.merge_and_unload()\n",
    "        else:\n",
    "            # Load full fine-tuned model\n",
    "            self.model = AutoModelForSequenceClassification.from_pretrained(adapter_path)\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        print(\"âœ“ Model loaded and ready for inference\")\n",
    "\n",
    "    def predict(self, texts, batch_size=32):\n",
    "        \"\"\"Make predictions with probabilities\"\"\"\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        probabilities = []\n",
    "\n",
    "        print(f\"Making predictions on {len(texts)} samples...\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                batch_texts = texts[i:i + batch_size]\n",
    "                \n",
    "                inputs = self.tokenizer(\n",
    "                    batch_texts,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    max_length=512,\n",
    "                    padding=True\n",
    "                ).to(self.device)\n",
    "\n",
    "                outputs = self.model(**inputs)\n",
    "                \n",
    "                # Get predictions\n",
    "                preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "                predictions.extend(preds)\n",
    "                \n",
    "                # Get probabilities for positive class\n",
    "                probs = torch.softmax(outputs.logits, dim=1)[:, 1].cpu().numpy()\n",
    "                probabilities.extend(probs)\n",
    "                \n",
    "                if (i // batch_size + 1) % 10 == 0:\n",
    "                    print(f\"  Processed {i + len(batch_texts)}/{len(texts)} samples\")\n",
    "\n",
    "        print(\"âœ“ Predictions complete\")\n",
    "        return np.array(predictions), np.array(probabilities)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 3. EVALUATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_sentiment_model(y_true, y_pred, y_proba=None, \n",
    "                            class_names=['Negative', 'Positive'],\n",
    "                            model_name='model'):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation\n",
    "    \n",
    "    Args:\n",
    "        y_true: Ground truth labels\n",
    "        y_pred: Predicted labels\n",
    "        y_proba: Prediction probabilities (optional)\n",
    "        class_names: Names of classes\n",
    "        model_name: Name for saving plots\n",
    "    \"\"\"\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Macro averages\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='macro', zero_division=0\n",
    "    )\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SENTIMENT CLASSIFICATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nOverall Accuracy: {accuracy*100:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nMacro Averages:\")\n",
    "    print(f\"  Precision: {precision_macro*100:.2f}%\")\n",
    "    print(f\"  Recall:    {recall_macro*100:.2f}%\")\n",
    "    print(f\"  F1-Score:  {f1_macro*100:.2f}%\")\n",
    "\n",
    "    print(\"\\nPer-Class Metrics:\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"{class_name} (n={support[i]}):\")\n",
    "        print(f\"  Precision: {precision[i]*100:.2f}%\")\n",
    "        print(f\"  Recall:    {recall[i]*100:.2f}%\")\n",
    "        print(f\"  F1-Score:  {f1[i]*100:.2f}%\")\n",
    "        print()\n",
    "\n",
    "    # Classification report\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot\n",
    "    cm_path = f'{model_name.replace(\"/\", \"_\")}_confusion_matrix.png'\n",
    "    plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"âœ“ Confusion matrix saved to {cm_path}\")\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'cm_plot_path': cm_path\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 4. MAIN EXECUTION EXAMPLE\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # ========== CONFIGURATION ==========\n",
    "    DB_PATH = r'/content/reviews_processed.db'\n",
    "    \n",
    "    # Model settings\n",
    "    MODEL_NAME = 'distilbert/distilbert-base-uncased'\n",
    "    USE_LORA = True  # Set to False for full fine-tuning\n",
    "    \n",
    "    # Training settings\n",
    "    EPOCHS = 3\n",
    "    BATCH_SIZE = 16\n",
    "    LEARNING_RATE = 3e-4 if USE_LORA else 2e-5  # Higher LR for LoRA\n",
    "    TEST_SIZE = 0.2\n",
    "    VAL_SIZE = 0.1\n",
    "    \n",
    "    # Paths\n",
    "    LORA_ADAPTER_PATH = './lora_sentiment_adapter'\n",
    "    FULL_MODEL_PATH = './full_sentiment_model'\n",
    "    \n",
    "    # ========== LOAD DATA ==========\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 1: LOADING DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load training data\n",
    "    review_text_clean = 'review_text_clean'\n",
    "    voted_up = 'voted_up'\n",
    "    train_df = load_data_from_sqlite(DB_PATH, 'train')\n",
    "    train_texts = train_df[review_text_clean].tolist()\n",
    "    train_labels = train_df[voted_up].tolist()\n",
    "    \n",
    "    # Load validation data\n",
    "    val_df = load_data_from_sqlite(DB_PATH, 'validation')\n",
    "    val_texts = val_df[review_text_clean].tolist()\n",
    "    val_labels = val_df[voted_up].tolist()\n",
    "    \n",
    "    # Load test data\n",
    "    test_df = load_data_from_sqlite(DB_PATH, 'test')\n",
    "    test_texts = test_df[review_text_clean].tolist()\n",
    "    test_labels = test_df[voted_up].tolist()\n",
    "    \n",
    "    print(f\"Training set:   {len(train_texts)} samples\")\n",
    "    print(f\"Validation set: {len(val_texts)} samples\")\n",
    "    print(f\"Test set:       {len(test_texts)} samples\")\n",
    "    \n",
    "    # ========== TRAIN MODEL WITH LORA ==========\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 3: TRAINING MODEL\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    classifier = SentimentClassifierWithLoRA(\n",
    "        model_name=MODEL_NAME,\n",
    "        num_labels=2,\n",
    "        use_lora=USE_LORA\n",
    "    )\n",
    "    \n",
    "    trainer = classifier.train(\n",
    "        train_texts=train_texts,\n",
    "        train_labels=train_labels,\n",
    "        val_texts=val_texts,\n",
    "        val_labels=val_labels,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        lora_output_dir=LORA_ADAPTER_PATH if USE_LORA else FULL_MODEL_PATH\n",
    "    )\n",
    "    \n",
    "    # ========== EVALUATE ON TEST SET ==========\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 4: EVALUATING MODEL (After Training)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    test_predictions, test_probabilities = classifier.predict(test_texts)\n",
    "    \n",
    "    results = evaluate_sentiment_model(\n",
    "        y_true=test_labels,\n",
    "        y_pred=test_predictions,\n",
    "        y_proba=test_probabilities,\n",
    "        class_names=['Negative', 'Positive'],\n",
    "        model_name=f\"{MODEL_NAME}_lora\" if USE_LORA else MODEL_NAME\n",
    "    )\n",
    "    \n",
    "    # ========== LOAD AND EVALUATE SAVED MODEL ==========\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 5: TESTING MODEL LOADING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Create new classifier instance\n",
    "    classifier_loaded = SentimentClassifierWithLoRA(\n",
    "        model_name=MODEL_NAME,\n",
    "        num_labels=2,\n",
    "        use_lora=USE_LORA\n",
    "    )\n",
    "    \n",
    "    # Load the saved model\n",
    "    model_path = LORA_ADAPTER_PATH if USE_LORA else FULL_MODEL_PATH\n",
    "    classifier_loaded.load_model(\n",
    "        adapter_path=model_path,\n",
    "        base_model_name=MODEL_NAME\n",
    "    )\n",
    "    \n",
    "    # Make predictions with loaded model\n",
    "    print(\"\\nMaking predictions with loaded model...\")\n",
    "    loaded_predictions, loaded_probabilities = classifier_loaded.predict(test_texts)\n",
    "    \n",
    "    # Evaluate loaded model\n",
    "    loaded_results = evaluate_sentiment_model(\n",
    "        y_true=test_labels,\n",
    "        y_pred=loaded_predictions,\n",
    "        y_proba=loaded_probabilities,\n",
    "        class_names=['Negative', 'Positive'],\n",
    "        model_name=f\"{MODEL_NAME}_loaded\"\n",
    "    )\n",
    "    \n",
    "    # Verify predictions match\n",
    "    predictions_match = np.array_equal(test_predictions, loaded_predictions)\n",
    "    print(f\"\\nâœ“ Loaded model predictions match original: {predictions_match}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PIPELINE COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n{'LoRA Adapter' if USE_LORA else 'Full Model'} saved to: {model_path}\")\n",
    "    print(f\"Test Accuracy: {results['accuracy']*100:.2f}%\")\n",
    "    print(f\"Test F1 (Macro): {results['f1'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
